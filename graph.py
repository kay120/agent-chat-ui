"""
LangGraph å›¾å®šä¹‰ - ç”¨äº langgraph_api
è¿™ä¸ªæ–‡ä»¶ä¸ä½¿ç”¨ç›¸å¯¹å¯¼å…¥ï¼Œå¯ä»¥è¢« langgraph_api ç›´æ¥åŠ è½½
"""
import os
from typing import Annotated
from typing_extensions import TypedDict
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage
from langgraph.graph import StateGraph, START, END, add_messages
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI


# å®šä¹‰çŠ¶æ€
class State(TypedDict):
    """å¯¹è¯çŠ¶æ€"""
    messages: Annotated[list[BaseMessage], add_messages]


# åˆå§‹åŒ– LLM
def get_llm():
    """è·å– LLM å®ä¾‹"""
    deepseek_api_key = os.getenv("DEEPSEEK_API_KEY", "")
    deepseek_base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    deepseek_model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")
    
    if not deepseek_api_key:
        raise ValueError("DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    llm = ChatOpenAI(
        model=deepseek_model,
        api_key=deepseek_api_key,
        base_url=deepseek_base_url,
        temperature=0.7,
        streaming=True
    )
    
    print(f"âœ… å·²åˆå§‹åŒ– DeepSeek æ¨¡å‹: {deepseek_model}")
    return llm


# åˆ›å»º LLM å®ä¾‹
llm = get_llm()


# å®šä¹‰èŠå¤©èŠ‚ç‚¹
def chatbot(state: State) -> State:
    """èŠå¤©èŠ‚ç‚¹"""
    print(f"ğŸ¤– Chatbot node called with {len(state['messages'])} messages")
    
    # è°ƒç”¨ LLM
    response = llm.invoke(state["messages"])
    
    # è¿”å›æ–°çŠ¶æ€
    return {"messages": [response]}


# åˆ›å»ºå›¾
def create_graph():
    """åˆ›å»º LangGraph"""
    workflow = StateGraph(State)

    # æ·»åŠ èŠå¤©èŠ‚ç‚¹
    workflow.add_node("chatbot", chatbot)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("chatbot")

    # æ·»åŠ ç»“æŸè¾¹
    workflow.add_edge("chatbot", END)

    # ç¼–è¯‘å›¾ï¼ˆä¸æä¾› checkpointerï¼Œè®© langgraph_api è‡ªåŠ¨å¤„ç†ï¼‰
    compiled_graph = workflow.compile()

    print("âœ… LangGraph åˆ›å»ºå®Œæˆ")
    return compiled_graph


# åˆ›å»ºå›¾å®ä¾‹ï¼ˆä¾› langgraph_api ä½¿ç”¨ï¼‰
graph = create_graph()


# LangChain ä¸ LangGraph åä½œæŒ‡å—

## ğŸ¯ æ ¸å¿ƒç†è§£

### åˆ†å·¥æ˜ç¡®

| æ¡†æ¶ | èŒè´£ | ç±»æ¯” |
|------|------|------|
| **LangChain** | æä¾›ç»„ä»¶å’Œå·¥å…· | å·¥å…·ç®±ã€é›¶ä»¶åº“ |
| **LangGraph** | ç¼–æ’å·¥ä½œæµç¨‹ | æµæ°´çº¿ã€ç»„è£…å›¾çº¸ |

### é…åˆæ–¹å¼

```
LangChain ç»„ä»¶ â†’ åœ¨ LangGraph èŠ‚ç‚¹ä¸­ä½¿ç”¨ â†’ æ„å»ºæ™ºèƒ½ä½“
```

---

## ğŸ“¦ LangChain æä¾›çš„ç»„ä»¶

### 1. LLM æ¨¡å‹

```python
from langchain.chat_models import init_chat_model

# ç»Ÿä¸€æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹
llm = init_chat_model("deepseek:deepseek-chat")
llm = init_chat_model("anthropic:claude-3")
llm = init_chat_model("openai:gpt-4")
```

### 2. æç¤ºè¯æ¨¡æ¿

```python
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "ä½ æ˜¯{role}"),
    ("human", "{question}")
])
```

### 3. å·¥å…·

```python
from langchain_core.tools import tool

@tool
def my_tool(param: str) -> str:
    """å·¥å…·æè¿°"""
    return result
```

### 4. å‘é‡æ•°æ®åº“

```python
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings

vectorstore = Chroma(
    collection_name="docs",
    embedding_function=OpenAIEmbeddings()
)
retriever = vectorstore.as_retriever()
```

### 5. è¾“å‡ºè§£æå™¨

```python
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser

parser = JsonOutputParser()
```

### 6. LCEL é“¾

```python
# LangChain Expression Language
chain = prompt | llm | output_parser
result = chain.invoke({"question": "..."})
```

---

## ğŸ”„ LangGraph æä¾›çš„ç¼–æ’èƒ½åŠ›

### 1. çŠ¶æ€ç®¡ç†

```python
from langgraph.graph import StateGraph
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]
    data: dict
```

### 2. èŠ‚ç‚¹å®šä¹‰

```python
def my_node(state: State):
    # åœ¨è¿™é‡Œä½¿ç”¨ LangChain ç»„ä»¶
    llm = init_chat_model("deepseek:deepseek-chat")
    result = llm.invoke(state["messages"])
    return {"messages": [result]}
```

### 3. æµç¨‹æ§åˆ¶

```python
workflow = StateGraph(State)
workflow.add_node("node1", node1_func)
workflow.add_node("node2", node2_func)

# å›ºå®šè¾¹
workflow.add_edge("node1", "node2")

# æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "node1",
    routing_function,
    {"path1": "node2", "path2": "node3"}
)
```

### 4. æŒä¹…åŒ–

```python
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = SqliteSaver.from_conn_string("memory.db")
app = workflow.compile(checkpointer=checkpointer)
```

---

## ğŸ¨ é…åˆæ¨¡å¼

### æ¨¡å¼ 1ï¼šLangChain ç»„ä»¶ä½œä¸ºèŠ‚ç‚¹

```python
# LangChain ç»„ä»¶
llm = init_chat_model("deepseek:deepseek-chat")
prompt = ChatPromptTemplate.from_messages([...])

# LangGraph èŠ‚ç‚¹
def llm_node(state):
    chain = prompt | llm
    result = chain.invoke(state)
    return {"output": result.content}

# æ·»åŠ åˆ°å·¥ä½œæµ
workflow.add_node("llm", llm_node)
```

### æ¨¡å¼ 2ï¼šLangChain å·¥å…· + LangGraph Agent

```python
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent

# LangChain å·¥å…·
@tool
def search(query: str) -> str:
    """æœç´¢å·¥å…·"""
    return "æœç´¢ç»“æœ..."

# LangGraph Agentï¼ˆå†…éƒ¨ä½¿ç”¨ LangChainï¼‰
agent = create_react_agent(
    model=llm,
    tools=[search]
)
```

### æ¨¡å¼ 3ï¼šLangChain Retriever + LangGraph å·¥ä½œæµ

```python
# LangChain Retriever
retriever = vectorstore.as_retriever()

# LangGraph èŠ‚ç‚¹
def retrieve_node(state):
    docs = retriever.invoke(state["question"])
    return {"documents": docs}

def generate_node(state):
    context = "\n".join([d.page_content for d in state["documents"]])
    chain = prompt | llm
    result = chain.invoke({"context": context, "question": state["question"]})
    return {"answer": result.content}

# å·¥ä½œæµ
workflow.add_node("retrieve", retrieve_node)
workflow.add_node("generate", generate_node)
workflow.add_edge("retrieve", "generate")
```

---

## ğŸš€ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹ 1ï¼šRAG ç³»ç»Ÿ

**LangChain æä¾›**ï¼š
- Embeddings
- VectorStore
- Retriever
- LLM
- Prompt

**LangGraph æä¾›**ï¼š
- æ£€ç´¢ â†’ ç”Ÿæˆçš„å·¥ä½œæµ
- è´¨é‡è¯„ä¼°å’Œé‡è¯•é€»è¾‘
- çŠ¶æ€ç®¡ç†

```python
# å·¥ä½œæµ
START â†’ æ£€ç´¢æ–‡æ¡£ â†’ ç”Ÿæˆç­”æ¡ˆ â†’ è¯„ä¼°è´¨é‡ â†’ END
                              â†“ (è´¨é‡ä¸å¥½)
                              â†‘____________|
```

### æ¡ˆä¾‹ 2ï¼šå¤šæ­¥éª¤ç ”ç©¶ Agent

**LangChain æä¾›**ï¼š
- LLMï¼ˆè§„åˆ’ã€åˆ†æã€æ’°å†™ï¼‰
- Toolsï¼ˆæœç´¢ã€æ•°æ®åˆ†æï¼‰
- Promptsï¼ˆä¸åŒè§’è‰²çš„æç¤ºè¯ï¼‰

**LangGraph æä¾›**ï¼š
- è§„åˆ’ â†’ æœç´¢ â†’ åˆ†æ â†’ æ’°å†™çš„æµç¨‹
- æ¯ä¸ªæ­¥éª¤çš„çŠ¶æ€ä¼ é€’
- æŒä¹…åŒ–ä¸­é—´ç»“æœ

```python
# å·¥ä½œæµ
START â†’ è§„åˆ’ â†’ æœç´¢ â†’ åˆ†æ â†’ æ’°å†™ â†’ END
```

### æ¡ˆä¾‹ 3ï¼šå¤š Agent å®¢æœç³»ç»Ÿ

**LangChain æä¾›**ï¼š
- ä¸åŒé…ç½®çš„ LLMï¼ˆè·¯ç”±ã€æŠ€æœ¯ã€é”€å”®ï¼‰
- Toolsï¼ˆè®¢å•æŸ¥è¯¢ã€äº§å“æŸ¥è¯¢ã€å·¥å•åˆ›å»ºï¼‰
- Promptsï¼ˆä¸åŒ Agent çš„è§’è‰²è®¾å®šï¼‰

**LangGraph æä¾›**ï¼š
- è·¯ç”±é€»è¾‘
- å¤šä¸ªä¸“ä¸š Agent çš„åä½œ
- å¯¹è¯å†å²ç®¡ç†

```python
# å·¥ä½œæµ
START â†’ åˆ†ç±»å™¨ â†’ æŠ€æœ¯ Agent â†’ END
                â†“ é”€å”® Agent â†’ END
                â†“ æŠ•è¯‰ Agent â†’ END
```

---

## ğŸ“Š å¯¹æ¯”è¡¨

| åŠŸèƒ½ | LangChain | LangGraph | é…åˆä½¿ç”¨ |
|------|-----------|-----------|---------|
| **LLM è°ƒç”¨** | âœ… æä¾›æ¥å£ | âŒ | LangChain LLM åœ¨ LangGraph èŠ‚ç‚¹ä¸­ |
| **æç¤ºè¯** | âœ… æ¨¡æ¿ç³»ç»Ÿ | âŒ | LangChain Prompt åœ¨èŠ‚ç‚¹ä¸­ |
| **å·¥å…·è°ƒç”¨** | âœ… @tool è£…é¥°å™¨ | âœ… ReAct Agent | LangChain å·¥å…· + LangGraph Agent |
| **å·¥ä½œæµ** | âš ï¸ ç®€å•é“¾å¼ | âœ… å¤æ‚çŠ¶æ€æœº | LangGraph ç¼–æ’ LangChain ç»„ä»¶ |
| **çŠ¶æ€ç®¡ç†** | âŒ | âœ… StateGraph | LangGraph ç®¡ç†çŠ¶æ€ |
| **æŒä¹…åŒ–** | âš ï¸ ç®€å•è®°å¿† | âœ… Checkpointer | LangGraph æŒä¹…åŒ– |
| **æ¡ä»¶è·¯ç”±** | âŒ | âœ… Conditional Edges | LangGraph æ§åˆ¶æµç¨‹ |
| **å¤š Agent** | âŒ | âœ… åŸç”Ÿæ”¯æŒ | LangGraph ç¼–æ’å¤šä¸ª LangChain Agent |

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. èŒè´£åˆ†ç¦»

```python
# âœ… å¥½çš„åšæ³•
# LangChain è´Ÿè´£"åšä»€ä¹ˆ"
llm = init_chat_model("deepseek:deepseek-chat")
tools = [search_tool, calculator_tool]

# LangGraph è´Ÿè´£"æ€ä¹ˆåš"
workflow = StateGraph(State)
workflow.add_node("think", think_node)
workflow.add_node("act", act_node)
workflow.add_edge("think", "act")
```

### 2. å¤ç”¨ LangChain ç»„ä»¶

```python
# âœ… å¥½çš„åšæ³•ï¼šå®šä¹‰ä¸€æ¬¡ï¼Œå¤šå¤„ä½¿ç”¨
llm = init_chat_model("deepseek:deepseek-chat")

def node1(state):
    return {"output": llm.invoke(state["input"])}

def node2(state):
    return {"output": llm.invoke(state["input"])}
```

### 3. ä½¿ç”¨ LCEL ç®€åŒ–èŠ‚ç‚¹

```python
# âœ… å¥½çš„åšæ³•ï¼šç”¨ LCEL ç»„åˆ LangChain ç»„ä»¶
chain = prompt | llm | output_parser

def node(state):
    result = chain.invoke(state)
    return {"output": result}
```

### 4. é¢„æ„å»º Agent + è‡ªå®šä¹‰èŠ‚ç‚¹

```python
# âœ… å¥½çš„åšæ³•ï¼šç»“åˆé¢„æ„å»ºå’Œè‡ªå®šä¹‰
from langgraph.prebuilt import create_react_agent

# ä½¿ç”¨é¢„æ„å»º Agent
agent = create_react_agent(model=llm, tools=tools)

# æ·»åŠ è‡ªå®šä¹‰å‰åå¤„ç†
workflow.add_node("preprocess", preprocess_node)
workflow.add_node("agent", agent)
workflow.add_node("postprocess", postprocess_node)
```

---

## ğŸ”§ å®ç”¨æŠ€å·§

### æŠ€å·§ 1ï¼šåœ¨èŠ‚ç‚¹ä¸­åŠ¨æ€é€‰æ‹© LLM

```python
def smart_node(state):
    # æ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©ä¸åŒçš„ LLM
    if state["complexity"] == "high":
        llm = init_chat_model("openai:gpt-4")
    else:
        llm = init_chat_model("deepseek:deepseek-chat")
    
    result = llm.invoke(state["messages"])
    return {"messages": [result]}
```

### æŠ€å·§ 2ï¼šåœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨å¤šä¸ª LangChain ç»„ä»¶

```python
def rag_node(state):
    # 1. æ£€ç´¢ï¼ˆLangChain Retrieverï¼‰
    docs = retriever.invoke(state["question"])
    
    # 2. é‡æ’åºï¼ˆLangChain Rerankerï¼‰
    reranked = reranker.compress_documents(docs, state["question"])
    
    # 3. ç”Ÿæˆï¼ˆLangChain LLMï¼‰
    context = "\n".join([d.page_content for d in reranked])
    chain = prompt | llm
    result = chain.invoke({"context": context, "question": state["question"]})
    
    return {"answer": result.content}
```

### æŠ€å·§ 3ï¼šæµå¼è¾“å‡º

```python
async def streaming_node(state):
    """åœ¨ LangGraph èŠ‚ç‚¹ä¸­ä½¿ç”¨ LangChain çš„æµå¼è¾“å‡º"""
    llm = init_chat_model("deepseek:deepseek-chat")
    
    full_response = ""
    async for chunk in llm.astream(state["messages"]):
        full_response += chunk.content
        # å¯ä»¥åœ¨è¿™é‡Œå‘é€ä¸­é—´ç»“æœ
    
    return {"messages": [AIMessage(content=full_response)]}
```

---

## ğŸ“š å­¦ä¹ è·¯å¾„

### ç¬¬ 1 æ­¥ï¼šæŒæ¡ LangChain åŸºç¡€
- LLM è°ƒç”¨
- Prompt æ¨¡æ¿
- å·¥å…·å®šä¹‰
- LCEL é“¾å¼è°ƒç”¨

### ç¬¬ 2 æ­¥ï¼šæŒæ¡ LangGraph åŸºç¡€
- StateGraph
- èŠ‚ç‚¹å’Œè¾¹
- æ¡ä»¶è·¯ç”±
- Checkpointer

### ç¬¬ 3 æ­¥ï¼šå­¦ä¹ é…åˆä½¿ç”¨
- åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨ LangChain ç»„ä»¶
- ä½¿ç”¨é¢„æ„å»º Agent
- æ„å»ºå¤æ‚å·¥ä½œæµ

### ç¬¬ 4 æ­¥ï¼šå®æˆ˜é¡¹ç›®
- RAG ç³»ç»Ÿ
- å¤šæ­¥éª¤ Agent
- å¤š Agent åä½œ

---

## ğŸ”— ç›¸å…³èµ„æº

- [å®Œæ•´ç¤ºä¾‹ä»£ç ](../../examples/intelligent_customer_service.py)
- [LangGraph å®Œæ•´æŒ‡å—](./LANGGRAPH_LANGCHAIN_1.0_GUIDE.md)
- [å¿«é€Ÿå‚è€ƒ](./LANGGRAPH_QUICK_REFERENCE.md)
- [ä»£ç æ”¹è¿›æŒ‡å—](./CODE_IMPROVEMENT_GUIDE.md)

---

**ç‰ˆæœ¬**: v1.0.0  
**æ›´æ–°**: 2025-01-16

